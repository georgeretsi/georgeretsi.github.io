---
layout: publication
title: "Pruning Neural Networks (ICIP 2021 & BMVC 2023)"
description: # ""
img: assets/img/feather.png
importance: 1
category: work
---

<style type="text/css">
  .post-title {
    text-align: center;
    font-family: "Google Sans", sans-serif;
    /* color: #363636; */
    font-size: 2rem;
    font-weight: 400;
    line-height: 1.125;
  }
  .publication-authors
  {
    margin-top: 15px;
    text-align: center;
    font-family: "Google Sans", sans-serif;
  }
  h3 {
    font-family: "Google Sans", sans-serif;
    /* color: #363636; */
    font-weight: 400;
    line-height: 1.125;
    text-align: center;
    margin-top: 30px;
    margin-bottom: 30px;
  }
  .btn {
    /*color: white;*/
    padding: .5rem 1.5rem;
    text-transform: none;
    font-size: 17px;
  }
  .btn span {
    /*color:white;*/
  }

  .btn:hover {
    text-decoration: underline;
  }

  .publication-icons {
    margin-top: 30px;
    margin-bottom: 30px;
  }

  .abstract {
    text-align: justify;
  }

</style>

<p class="abstract">
Neural Network pruning is an increasingly popular way for producing compact and efficient models, suitable for resource-limited environments, while preserving high performance. While the pruning can be performed using a multi-cycle training and fine-tuning process, the recent trend is to encompass the sparsification process during the standard course of training. 
We focus on online (during training) and unstructured pruning. In other words, we aim to sparsify the weight tensor of deep neural networks.
</p>

<div class="row">
  <div class="col-sm" align=center>
    <h4>Online Weight Pruning Via Adaptive Sparsity Loss</h4>
  </div>
</div>

<div class="row publication-icons">
  <div class="col-sm" align=center>
        <!-- PDF Link. -->
        <!-- Video Link. -->
        <a class="btn btn-dark btn-rounded" href="https://arxiv.org/pdf/2006.02768.pdf" role="button">
          <i class="fa fa-file-pdf"></i>
          Paper
        </a>
        <a class="btn btn-dark" href="https://arxiv.org/pdf/2006.02768" role="button">
          <i class="ai ai-arxiv"></i>
          arXiv
        </a>
        <!-- Code Link. -->
        <!-- Github -->
        <a class="btn btn-dark" href="https://github.com/georgeretsi/SparsityLoss" role="button">
          <i class="fab fa-github"></i>
          Code
        </a>
  </div>
</div>

<div class="row">
  <div class="col-sm" align=center>
    <h4>Feather: An Elegant Solution to Effective DNN Sparsification</h4>
  </div>
</div>

<div class="row publication-icons">
  <div class="col-sm" align=center>
        <!-- PDF Link. -->
        <!-- Video Link. -->
        <a class="btn btn-dark btn-rounded" href="https://arxiv.org/pdf/2310.02448.pdf" role="button">
          <i class="fa fa-file-pdf"></i>
          Paper
        </a>
        <a class="btn btn-dark" href="https://arxiv.org/abs/2310.02448" role="button">
          <i class="ai ai-arxiv"></i>
          arXiv
        </a>
        <!-- Code Link. -->
        <!-- Github -->
        <a class="btn btn-dark" href="https://github.com/athglentis/feather" role="button">
          <i class="fab fa-github"></i>
          Code
        </a>
  </div>
</div>

<!-- <div class="alert alert-info">
<b>tl;dr:</b> we improve 3D facial reconstruction in videos by focusing on the lip formations and mouth movements, using a <b>lipreading</b> loss
</div> -->

